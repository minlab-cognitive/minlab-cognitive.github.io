<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training | ICCLab [I-see-lab]</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Summary:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.
In preparation for submission.
A preliminary version is available here: [

Restricted-RNN training framework]
">
    <meta name="generator" content="Hugo 0.124.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    
      <meta name="author" content = "Yiteng Zhang, Xingyu Li">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      
<link rel="shortcut icon" href="/images/logo.png" type="image/x-icon" />


    

    

    
      <link rel="canonical" href="https://minlab-cognitive.github.io/posts/rrnn/">
    

    <meta property="og:title" content="Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training" />
<meta property="og:description" content="Summary:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.
In preparation for submission.
A preliminary version is available here: [

Restricted-RNN training framework]
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://minlab-cognitive.github.io/posts/rrnn/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-03-10T01:20:10+08:00" />
<meta property="article:modified_time" content="2025-03-10T01:20:10+08:00" />
<meta itemprop="name" content="Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training">
<meta itemprop="description" content="Summary:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.
In preparation for submission.
A preliminary version is available here: [

Restricted-RNN training framework]
"><meta itemprop="datePublished" content="2025-03-10T01:20:10+08:00" />
<meta itemprop="dateModified" content="2025-03-10T01:20:10+08:00" />
<meta itemprop="wordCount" content="167">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training"/>
<meta name="twitter:description" content="Summary:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.
In preparation for submission.
A preliminary version is available here: [

Restricted-RNN training framework]
"/>

	

  
    

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>



  
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  <header class="cover bg-top" style="background-image: url('https://minlab-cognitive.github.io/images/works/rrnn-draft.png');">
    <div class="bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        ICCLab [I-see-lab]
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About Our Lab page">
              About Our Lab
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/posts/" title="Featured Works page">
              Featured Works
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <div class="f2 f1-l fw2 white-90 mb0 lh-title">Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training</div>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Featured Works
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training</h1>
      
      <p class="tracked">
        By <strong>Yiteng Zhang, Xingyu Li</strong>
      </p>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-03-10T01:20:10+08:00">March 10, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p><strong>Summary</strong>:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.</p>
<p><strong>In preparation for submission.</strong><br>
<strong>A preliminary version is available here:</strong> [

<a href="/files/InterpretableRNN_20250509v3.pdf">Restricted-RNN training framework</a>]<br></p>
<!-- **Title**: Mental Programming of Spatial Sequences in Working Memory in Macaque Frontal Cortex<br>
**DOI**: <a href="https://doi.org/10.1126/science.adp6091" target="_blank">10.1126/science.adp6091</a> -->
<figure><img src="/images/works/rrnn-draft.png" width="500">
</figure>

<!-- ## Highlights

to be updated --><ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-dark-blue-80 bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://minlab-cognitive.github.io/" >
    &copy;  ICCLab [I-see-lab] 2025 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>

