<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>The Interpretable Cognitive Computation Lab | ICCLab [I-see-lab]</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="">
    <meta name="generator" content="Hugo 0.124.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      
<link rel="shortcut icon" href="/images/logo.png" type="image/x-icon" />


    

    
    
      <link href="/index.xml" rel="alternate" type="application/rss+xml" title="ICCLab [I-see-lab]" />
      <link href="/index.xml" rel="feed" type="application/rss+xml" title="ICCLab [I-see-lab]" />
      
    

    
      <link rel="canonical" href="https://minlab-cognitive.github.io/">
    

    <meta property="og:title" content="The Interpretable Cognitive Computation Lab" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://minlab-cognitive.github.io/" />
<meta itemprop="name" content="The Interpretable Cognitive Computation Lab">
<meta itemprop="description" content=""><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="The Interpretable Cognitive Computation Lab"/>
<meta name="twitter:description" content=""/>

	

  
    

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)']]                  
    }
  };
</script>



  
  </head>

  <body class="ma0 avenir bg-near-white">

    

  <header>
    <div class="pb3-m pb6-l bg-dark-blue-80">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        ICCLab [I-see-lab]
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About Our Lab page">
              About Our Lab
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/posts/" title="Featured Works page">
              Featured Works
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

      <div class="tc-l pv3 ph3 ph4-ns">
        <h1 class="f2 f-subheadline-l fw4 gold mb0 lh-title">
          The Interpretable Cognitive Computation Lab
        </h1>
        
      </div>
    </div>
  </header>


    <main class="pb7" role="main">
      
  <article class="cf ph3 ph5-l pv3 pv4-l f4 tl-l center measure-wide-x lh-copy mid-gray">
      <p>Welcome to the Interpretable Cognitive Computation Lab (ICCLab [I-see-lab])! Our team is dedicated to <em>unraveling the fundamental computational principles that drive complex intelligent behaviors</em> and <em>developing novel brain-inspired algorithms</em>. To do so, we adopt an approach that seamlessly integrates deep learning models, cutting-edge data analysis methods, and novel experimental data, with a strong focus on model interpretabilityâ€”an essential property setting us apart from the traditional black-box approach of many deep learning models.</p>
<p>Our current research focuses on</p>
<ul>
<li>Cognitive computational modeling</li>
<li>Neural data analysis</li>
<li>Brain-inspired computing</li>
</ul>
<p>Explore our featured works below, and don&rsquo;t hesitate to contact us <a href="mailto:minbin@lglab.ac.cn" target="_blank">[minbin@lglab.ac.cn]</a> with any questions!</p>

    </article>
    
    
    
    
    
    
    
    
    
    
    
      <div class="pa3 pa4-ns w-100 w-70-ns center">
        
        
            <h1 class="flex-none">
              Recent Featured Works
            </h1>
          

        

        <section class="w-100 mw8">
          
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/rrnn/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/rrnn-draft.png" class="img" alt="image from Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/rrnn/" class="color-inherit dim link">
            Discovering Novel Circuit Mechanisms in Higher Cognition through Interpretable Recurrent Neural Network Training
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
Training recurrent neural networks (RNNs) has revolutionized the way how systems neuroscientists form hypothesis when studying circuit mechanisms in various problems. However, the trained RNNs oftentimes are difficult to be interpreted, inconsistent with neural data or not necessarily comprising the full set of biological solutions. Here, we developed an interpretable RNN training framework, namely Restricted-RNN, capable of generating interpretable circuit hypothesis through a multilevel proposing-and-testing procedure that seamlessly integrates computational-, collective- and implementational-level descriptions. We demonstrated its validity in identifying data-compatible circuit mechanisms through a variety of macaque cognitive tasks, including parametric working memory, sequence working memory and perceptual decision-making. The key derived predictions were confirmed by monkey prefrontal and parietal neurophysiological data. Critically, the interpretable nature of Restricted-RNN endowed us a unified theory to explain the seemingly disparate phenomena across different tasks with a novel neural control state space, providing an intriguing geometric understanding for the ubiquitous control in cognitive processes.</p>
<p><strong>In preparation for submission.</strong><br>
<strong>A preliminary version is available here:</strong> [

<a href="/files/InterpretableRNN_20250509v3.pdf">Restricted-RNN training framework</a>]<br></p>
<!-- **Title**: Mental Programming of Spatial Sequences in Working Memory in Macaque Frontal Cortex<br>
**DOI**: <a href="https://doi.org/10.1126/science.adp6091" target="_blank">10.1126/science.adp6091</a> -->
        </div>
          <a href="/posts/rrnn/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/selection-vector/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/selection-vec.jpg" class="img" alt="image from Selection mechanism for flexible cognitive control">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/selection-vector/" class="color-inherit dim link">
            Selection mechanism for flexible cognitive control
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
Our research explores the neural mechanisms behind context-dependent decision-making (CDM) in humans and animals, focusing on discriminating between two selection mechanisms: input modulation and selection vector modulation. Using low-rank neural network modeling, we discovered that while input modulation is achievable with rank-one networks, additional dimensions are necessary for selection vector modulation. Through detailed information flow analysis, we revealed how these dimensions facilitate this modulation and identified new neural dynamical signatures at both neuron and population levels. Our findings offer a theoretical framework linking network connectivity and neural dynamics, advancing the understanding of circuit mechanisms in context-dependent computation.</p>
<p>This work was published in eLife [<strong>important</strong> and <strong>convincing</strong>].<br>
<strong>Title</strong>: Elucidating the selection mechanisms in contextdependent computation through low-rank neural network modeling<br>
<strong>eLife link here</strong>:<a href="https://doi.org/10.7554/eLife.103636.3" target="_blank">
<a href="https://doi.org/10.7554/eLife.103636.3" target="_blank" rel="noopener">https://doi.org/10.7554/eLife.103636.3</a></a></p>
        </div>
          <a href="/posts/selection-vector/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/kernel/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/kernel.jpg" class="img" alt="image from Temporal weighting of sensory evidence">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/kernel/" class="color-inherit dim link">
            Temporal weighting of sensory evidence
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
We introduced a rank-1 neural circuit model to account for diverse types of integration kernels in click-version perceptual decision making task. Equipped with data-driven optimization pipeline, the rank-1 model fits human behavior well, in a way comparable to the state-of-art divisive normalization models and leaky competitive accumulators. Furthermore, the rank-1 network gain insights at both colelctive and single neuron levels. At collective level, we propose alternative hypothesis of neural mechanisms underlying diverse types of integration kernels through collective dynamics compared with divisive models. At single neuron level, the rank-1 network exhibited heterogenous single neuron response kernels, resembling the diversity observed in neurophysical recordings, which can be explained by the combination of behavior and input kernels.</p>
<!-- This work is being submitted to PLOS Computational Biology .<br> -->
<p>This work has been accepted by the Journal of Computational Neuroscience and will be available online soon.<br>
<strong>Title</strong>: A solvable neural circuit model revealing the dynamical principle of non-optimal temporal weighting in perceptual decision making<br>
<strong>pdf available at</strong>:<a href="https://www.biorxiv.org/content/10.1101/2024.12.10.627688v1.full.pdf" target="_blank">biorxiv</a></p>
        </div>
          <a href="/posts/kernel/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/switch/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/summary-switch.png" class="img" alt="image from Flexible cognitive control: manipulating content in working memory">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/switch/" class="color-inherit dim link">
            Flexible cognitive control: manipulating content in working memory
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
Tian et al. investigated mental sorting using high-throughput electrophysiological recordings in the frontal cortex of macaque monkeys, memorizing and sorting spatial sequences in forward or backward orders according to visual cues. We discovered that items at each ordinal rank in WM were encoded in separate rank-WM subspaces and then, depending on cues, maintained or reordered between the subspaces, accompanied by two extra temporary subspaces in two operation steps. Furthermore, the cue activity served as an indexical signal to trigger sorting processes. Thus, we proposed a complete conceptual framework, where the neural landscape transitions in frontal neural states underlie the symbolic system for mental programming of sequence WM.</p>
<p>This work was published in Science in 2024.<br>
<strong>Title</strong>: Mental Programming of Spatial Sequences in Working Memory in Macaque Frontal Cortex<br>
<strong>DOI</strong>: <a href="https://doi.org/10.1126/science.adp6091" target="_blank">10.1126/science.adp6091</a></p>
        </div>
          <a href="/posts/switch/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/geodtr/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/geodtr-comb.jpg" class="img" alt="image from Cross-view Geolocalization via Geometric layout Disentanglement">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/geodtr/" class="color-inherit dim link">
            Cross-view Geolocalization via Geometric layout Disentanglement
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
The arrangement of objects provides clues for human to efficiently compare images from different view-angles while standard deep learning models focus naively on feature distances. Importantly, the correspondance between layouts of different views adheres to geometric constrains that are independent to the contents such as object textures. Based on this insight, we developed a network model with a dedicated pathway to capture the geometric layouts in the images. This layout modulates the raw features to facilitate efficient comparisons. Extensive experiments demonstrate the superiority of our model in generalizability across different areas.</p>
<p>This work was published in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) in 2024.<br>
<strong>Title</strong>: GeoDTR+: Toward Generic Cross-View Geolocalization via Geometric Disentanglement<br>
<strong>DOI</strong>: <a href="https://doi.org/10.1109/tpami.2024.3443652" target="_blank">10.1109/tpami.2024.3443652</a></p>
        </div>
          <a href="/posts/geodtr/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
            <div class="relative w-100 mb4">
              
<article class="bb b--black-10">
  <div class="db pv4 ph3 ph0-l no-underline dark-gray">
    <div class="flex flex-column flex-row-ns">
      
          
        <div class="pr3-ns mb4 mb0-ns w-100 w-40-ns">
          <a href="/posts/entry-flexible-control/" class="db grow">
            <img src="https://minlab-cognitive.github.io/images/works/entry.png" class="img" alt="image from Flexible cognitive control: entry of sequence working memory">
          </a>
        </div>
      
      <div class="blah w-100 w-60-ns pl3-ns">
        <h1 class="f3 fw1 athelas mt0 lh-title">
          <a href="/posts/entry-flexible-control/" class="color-inherit dim link">
            Flexible cognitive control: entry of sequence working memory
            </a>
        </h1>
        <div class="f6 f5-l lh-copy nested-copy-line-height nested-links">
          <p><strong>Summary</strong>:
Chen et al. discovered the separable and generalizable subspaces for sensory and sequence working memory in macaque frontal neural states. The neural activities and their dynamics within these subspaces reflected the flexible control of sequence working memory in various sequence sorting tasks, predicting monkeysâ€™ behavior in single trials.</p>
<p>This work was published in Neuron in 2024.<br>
<strong>Title</strong>: Flexible control of sequence working memory in the macaque frontal cortex<br>
<strong>DOI</strong>: <a href="https://doi.org/10.1016/j.neuron.2024.07.024" target="_blank">10.1016/j.neuron.2024.07.024</a></p>
        </div>
          <a href="/posts/entry-flexible-control/" class="ba b--moon-gray bg-light-gray br2 color-inherit dib f7 hover-bg-moon-gray link mt2 ph2 pv1">read more</a>
        
      </div>
    </div>
  </div>
</article>

            </div>
          
        </section>

        
        <section class="w-100">
          <h1 class="f3">More</h1>
          
          
            <h2 class="f5 fw4 mb4 dib mr3">
              <a href="/posts/sequence-wm/" class="link black dim">
                Geometry of sequence working memory
              </a>
            </h2>
          

          
          
            <a href="/posts/" class="link db f6 pa2 br3 bg-mid-gray white dim w4 tc">All Featured Works</a>
          
          </section>
        

        </div>
    
  

    </main>
    <footer class="bg-dark-blue-80 bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://minlab-cognitive.github.io/" >
    &copy;  ICCLab [I-see-lab] 2025 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>

